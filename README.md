**Step 01: Implement a simulation environment.** <br />
Must haves : environment must be a 2D grid of size M X N. <br />
Environment must be initialized with some dirt randomly on X% of grids. <br />
One grid can have more dirt than another grid. <br />
Must have a performance measure. 

**Step 02: Implement a randomized agent.** <br />
Think of this as a malfunctioning vacuum cleaner. <br />
Randomized agent will move up, down, left, right or suck irrespective of what it percepts. <br />

**Step 03: Implement a reflex agent.** <br />
A agent that selects actions on the basis of the current percept. <br />
A reflex agent will move up, down, left, right or suck depeding on the current precept. <br />

**Step 04: Implement a model based reflex agent.** <br />
A agent that selects actions on the basis of the percept history. <br />
A model based reflex agent will move up, down, left, right or suck depending on the precept history. <br />

**Step 05: Run simulations.** <br />
Report average performance of 100 runs,  for all three types of agents on grid sizes (5X5), (10 X 10), (100 X 100). <br />
